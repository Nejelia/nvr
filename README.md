# ATM CCTV (Raspberry Pi 4, 4×USB cams)

Система видеонаблюдения банкомата: FaceID (LBPH), детекция движения с масками, логирование событий и удобное web‑приложение.

## Возможности
- Поддержка до 4 USB‑камер на Raspberry Pi 4
- Режимы на камеру: **FaceID**, **Motion**, **Record on motion** (запись при движении)
- Face DB: добавление/удаление пользователей (по фото или кадру с камеры), обучение LBPH
- Маски движения: чёрно‑белые PNG‑маски «где смотреть»
- Просмотр потоков всех камер в браузере (MJPEG)
- Логи событий: входы по FaceID, события движения, начало/конец записи

## Структура
```
atm_cctv_pi/
  app/
    camera.py         # захват камер, режимы, запись по движению
    face.py           # FaceDB на LBPH (opencv-contrib)
    motion.py         # MOG2 + бинарная маска
    storage.py        # папки, логгер
    stream.py         # MJPEG-генератор
    web.py            # Flask-приложение
  data/
    faces/            # лица по папкам + lbph_model.yml/labels.json
    masks/            # cam{N}_mask.png
    logs/
    recordings/
  templates/          # простые HTML-страницы (Dashboard, Logs, Face DB, Masks)
  static/
  config.yaml
  requirements.txt
  run.sh
```

## Установка (Raspberry Pi OS Bookworm/Bullseye)
1. Обновить систему и поставить системный OpenCV (рекомендуется для Pi):
   ```bash
   sudo apt update
   sudo apt install -y python3-opencv libatlas-base-dev libopenblas-dev liblapack-dev
   ```
2. (Опционально) Если в системной сборке нет модуля `cv2.face` (LBPH), установите contrib‑сборку из pip:
   ```bash
   sudo pip3 install --no-cache-dir opencv-contrib-python
   ```
   > На слабых моделях сборка может быть тяжёлой. Альтернатива — использовать только детекцию без опознания.
3. Зависимости веб‑части:
   ```bash
   python3 -m pip install -r requirements.txt
   ```

## Запуск
```bash
cd atm_cctv_pi
./run.sh
# Откройте в браузере: http://<IP_вашего_RPi>:8080/
```

Если хотите вручную:
```bash
export FLASK_APP=app/web.py
python3 -m gevent.pywsgi -w 1 -b 0.0.0.0:8080 "app.web:create_app()"
```

## Режимы пользователя и администратора

### Пользователь: выполнение программы
1. Включите Raspberry Pi Zero 2.
2. Дождитесь загрузки операционной системы и автоматического запуска веб‑приложения.
3. Подключитесь к веб‑интерфейсу с ноутбука или телефона в той же сети.

**Основной сценарий использования:**
1. Пользователь подходит к камере на расстоянии 20–30 см.
2. Система автоматически выполняет детекцию лица.
3. Если лицо найдено в базе, система распознаёт пользователя.
4. Информация о доступе фиксируется в логах.
5. Ожидаемое время обработки: 5–7 секунд.

### Обращение к программе и доступ
- Программа запускается автоматически при старте Raspberry Pi Zero 2 (например, через `systemd`) либо вручную администратором.
- После запуска доступ осуществляется через веб‑браузер по адресу:
  `http://<IP-адрес Raspberry Pi>:8080`

#### Выполнение функции биометрической аутентификации
1. Подойдите к камере.
2. Дождитесь, пока система определит лицо.
3. При успешном распознавании информация фиксируется в логах и отображается в веб‑интерфейсе.

Регистрация новых пользователей выполняется администратором через веб‑интерфейс в разделе управления базой лиц.

### Завершение работы
- Программа завершает работу при выключении Raspberry Pi Zero 2.
- Администратор может остановить процесс вручную (Ctrl+C в терминале или остановка `systemd`‑сервиса).

### Сообщения пользователю
В процессе работы система может отображать:
- видеопоток с подключённых камер в режиме реального времени;
- визуальный статус работы камеры (включена или выключена);
- результат распознавания лица (имя пользователя либо сообщение о нераспознавании);
- уведомление о факте обнаружения движения в кадре.

### Администратор: контроль и журналы
Контроль работы камер, детекции движения и распознавания лиц осуществляется автоматически программой в фоновом режиме и не требует постоянного вмешательства администратора. В случае ошибки (например, отключение камеры) информация фиксируется в журнале событий.

**Сообщения и журналы для администратора:**
- файл логирования системы видеонаблюдения;
- журнал событий (движение, распознавание лиц, ошибки камер);
- журнал ошибок приложения.

Логи используются для диагностики неисправностей, анализа инцидентов и проверки корректности работы системы.

## Маски движения (как в примере)
- Для каждой камеры используется файл `data/masks/cam{N}_mask.png`.
- Это **чёрно‑белое PNG‑изображение** с размером, равным видео (по умолчанию 640×480).
- **Белое = учитывать движение**, **чёрное = игнорировать**.
- В веб‑UI можно скачать текущую маску, поправить в любом редакторе (GIMP, Paint), и загрузить обратно.

## FaceID (LBPH)
- База лиц хранится в `data/faces/<ФИО>/`. Вы можете:
  - Загрузить фото с лицом (UI → Face DB → Upload) — система сама вырежет лицо, нормализует и положит в папку.
  - Снять кадр с камеры (выберите камеру и нажмите Add / Train).
- После добавления система **переобучит** LBPH и сохранит `lbph_model.yml` и `labels.json`.
- Порог совпадения настраивается в `app/camera.py` (`conf < 80` — эмпирически для LBPH; подберите под свой датасет).

## Веб‑приложение
- **Dashboard**: предпросмотр стримов, выбор режима по каждой камере, запуск/останов.
- **Logs**: просмотр последних 1000 строк файла `data/logs/events.log`.
- **Face DB**: добавление/удаление людей, переобучение.
- **Motion Masks**: выгрузить/загрузить маску на камеру.

### Режимы
- **Face** — в онлайне ищет лица и пишет события в логи; прямой поток отображается в UI.
- **Motion** — детекция движения с учётом маски; события в логах.
- **Record on motion** — не пишет постоянно, но начинает запись `data/recordings/` при движении (хвост 5 секунд «после»).

## Настройка
Откройте `config.yaml`:
- `cameras`: индексы устройств (0..3). Проверьте `ls /dev/video*` или движением камер в UI.
- `video`: разрешение и FPS (по умолчанию 640×480@15 — оптимально для Pi4).
- `face`: параметры LBPH и детектора Хаара.
- `motion`: параметры MOG2 и пороги площадей контуров.

## Логи
Все события (`INFO`) пишутся в `data/logs/events.log` с ротацией (до ~2 МБ, 5 бэкапов).

## Советы по производительности на RPi4
- Ставьте MJPEG (в `config.yaml` fourcc: MJPG) и 640×480/15fps.
- Не включайте FaceID на всех четырёх камерах одновременно, если не нужно.
- По возможности используйте активные USB‑хабы и качественные кабели.
- Если CPU высокий, уменьшите FPS до 10 и `motion.min_contour_area`.

## API (минимум для интеграции)
- `POST /api/start` — `{ "modes": { "0": "face", "1": "motion", "2": "on_motion", "3": null } }`
- `POST /api/stop` — останавливает все
- `GET /api/status` — состояния камер

## Из примера проекта
- Маски движения — такой же принцип: ч/б PNG, белое=зона детекции.
- Логика FaceID — использует OpenCV LBPH, совместим с библиотеками из примера.
- При необходимости вы можете перенести датасет из вашего архива в `data/faces/`.

---

### Known limitations
- LBPH даёт условную биометрию; для банковского FaceID в проде требуется сертифицированная библиотека и liveness.
- MJPEG‑стримы без авторизации — поставьте обратный прокси (nginx) с auth, если нужно.


## Снимки и клиппинги событий (минимальный размер)
- При событии (движение или FaceID) система:

  - сохраняет **мини‑снимок** 320×240 JPEG (качество ~70) в `data/events/thumbs/`

  - пишет **короткий клип** ~2с до и ~3с после события (в сумме ~5с), AVI (XVID) 320×240, в `data/events/clips/`

  - добавляет в лог строку формата: `EVENT cam=<id> meta=<json> snapshot=<file> clip=<file>`

- На странице **Logs** такие строки визуализируются превью и ссылкой на клип.

- Встроено «debounce» ~1.5с, чтобы не плодить файлы при всплесках.
